# 小红书爬虫功能完整说明

## 📋 功能概览

参考 [MediaCrawler](https://github.com/suse00544/MediaCrawler) 项目，已实现以下功能：

### ✅ 已实现功能

1. **关键词搜索** - 根据关键词搜索笔记
2. **指定帖子ID抓取** - 批量获取指定ID的笔记详情（新）
3. **评论和二级评论** - 支持获取评论及回复，可配置数量（新）
4. **作者主页抓取** - 获取指定用户的所有笔记（新）
5. **评论词云图** - 根据评论生成词云图（新）
6. **登录态缓存** - 自动缓存和管理登录状态（新）
7. **IP代理池** - 支持代理轮换，防止IP被封（新）

---

## 🔐 登录态缓存（Session Cache）

### 什么是登录态缓存？

**登录态缓存**是将登录后的 Cookie 信息（特别是 `a1` 字段）保存到本地文件，避免每次爬取都需要重新登录。

### 工作原理

```
首次登录 → 保存Cookie到缓存文件 → 后续启动自动加载 → 过期后重新登录
```

1. **首次登录**: 用户通过 Cookie 登录后，系统自动保存 Cookie 到 `crawler/cache/xhs_session.json`
2. **后续使用**: 爬虫启动时自动从缓存加载 Cookie，无需重新登录
3. **过期管理**: Cookie 有过期时间（默认24小时），过期后需要重新登录

### 优势

- ✅ **提高效率**: 不需要每次都登录，节省时间
- ✅ **降低风险**: 减少登录频率，降低被封风险
- ✅ **多账号支持**: 可以为不同账号保存不同的登录态
- ✅ **自动管理**: 系统自动处理缓存和过期，无需手动操作

### 缓存文件

- **位置**: `crawler/cache/xhs_session.json`
- **内容**: Cookie字典、创建时间、过期时间
- **格式**: JSON格式，便于查看和调试

### 使用示例

```python
# 缓存功能默认开启，无需配置
# 如果需要手动清除缓存：
from xhs.cache import SessionCache
cache = SessionCache()
cache.clear()  # 清除缓存
```

---

## 🌐 IP代理池（Proxy Pool）

### 什么是IP代理池？

**IP代理池**是一组可用的代理服务器列表，爬虫可以轮换使用这些代理来发送请求，避免单一IP被平台封禁。

### 为什么需要代理池？

1. **防止IP被封**: 频繁请求同一IP容易被平台检测并封禁
2. **提高成功率**: 使用多个IP轮换，降低单IP请求频率
3. **模拟真实用户**: 不同IP看起来像不同用户，更自然
4. **突破地域限制**: 可以使用不同地区的IP访问内容

### 代理类型

| 类型 | 说明 | 格式示例 |
|------|------|----------|
| **HTTP/HTTPS** | 最常见的代理类型 | `http://user:pass@proxy.com:8080` |
| **SOCKS5** | 更安全，支持TCP和UDP | `socks5://user:pass@proxy.com:1080` |
| **住宅代理** | 真实用户IP，更难被检测（推荐） | `http://residential-proxy.com:8080` |
| **数据中心代理** | 速度快但容易被识别 | `http://datacenter-proxy.com:8080` |

### 工作原理

```
请求1 → 使用代理1 → 成功
请求2 → 使用代理2 → 成功
请求3 → 使用代理3 → 失败 → 标记为失败 → 使用代理4
...
所有代理失败 → 重置失败列表 → 重新开始轮询
```

1. **代理轮询**: 每次请求自动切换到下一个代理
2. **失败处理**: 如果代理失败，自动标记并跳过
3. **自动恢复**: 所有代理失败后，重置失败列表

### 使用方式

```python
from xhs.proxy_pool import ProxyPool

# 创建代理池
proxies = [
    "http://user:pass@proxy1.com:8080",
    "http://user:pass@proxy2.com:8080",
    "socks5://user:pass@proxy3.com:1080",
]
proxy_pool = ProxyPool(proxies)

# 在客户端中使用
client = XiaoHongShuClient(
    playwright_page=page,
    cookie_dict=cookies,
    proxy_pool=proxy_pool  # 传入代理池
)
```

### 代理获取建议

#### 1. 免费代理（不推荐）
- ❌ 可用性低，速度慢
- ❌ 稳定性差，经常失效
- ✅ 适合测试和小规模爬取

#### 2. 付费代理服务（推荐）
- ✅ **Luminati**: 全球最大代理网络
- ✅ **Smartproxy**: 性价比高
- ✅ **Oxylabs**: 稳定性好
- ✅ 适合大规模爬取

#### 3. 自建代理
- ✅ 使用云服务器搭建
- ✅ 成本可控，但需要维护
- ✅ 适合有技术团队的项目

### 注意事项

⚠️ **重要提示**:
- 代理池不是必须的，小规模爬取可以不使用
- 使用代理会增加请求延迟（50-200ms）
- 确保代理服务稳定可靠
- 遵守平台使用规则，不要过度爬取
- 建议使用住宅代理，更难被检测

---

## 🚀 新增API功能

### 1. 指定帖子ID批量抓取

**API**: `POST /api/xhs/notes/by-ids`

批量获取指定ID的笔记详情，适合已知笔记ID的场景。

```typescript
// 前端调用
const result = await getXHSNotesByIds([
  "note_id_1",
  "note_id_2", 
  "note_id_3"
]);

// 返回
{
  success: true,
  notes: [...],  // 笔记详情数组
  total: 3,
  fetched: 3
}
```

### 2. 评论和二级评论（可配置）

**API**: `POST /api/xhs/comments`

支持获取评论及二级评论（回复），可配置获取数量。

```typescript
// 前端调用
const result = await getXHSComments(
  note_id,
  xsec_token,
  cursor,
  10,        // num: 获取10条评论
  true       // get_sub_comments: 获取二级评论
);

// 返回
{
  success: true,
  has_more: false,
  cursor: "...",
  comments: [
    {
      id: "...",
      content: "评论内容",
      user: {...},
      like_count: 10,
      sub_comments: [  // 二级评论
        {
          id: "...",
          content: "回复内容",
          reply_to_user: "被回复的用户名",
          ...
        }
      ]
    }
  ]
}
```

### 3. 作者主页抓取

**API**: 
- `POST /api/xhs/user/notes` - 获取用户笔记列表
- `POST /api/xhs/user/info` - 获取用户信息

```typescript
// 获取用户笔记
const notes = await getUserNotes(
  user_id,
  cursor,
  20  // 每页数量
);

// 获取用户信息
const info = await getUserInfo(user_id);
// 返回: 昵称、简介、头像、粉丝数、笔记数等
```

### 4. 评论词云图生成

**API**: `POST /api/xhs/wordcloud`

根据评论文本生成词云图，可视化评论热点。

```typescript
// 前端调用
const comments = ["评论1", "评论2", "评论3", ...];
const result = await generateWordCloud(comments);

// 返回
{
  success: true,
  image: "data:image/png;base64,..."  // Base64图片
}
```

---

## 📦 安装新依赖

```bash
cd crawler
pip install wordcloud jieba pillow
```

---

## 🔧 配置说明

### 登录态缓存配置

缓存功能默认开启，无需配置。缓存文件位置：
```
crawler/cache/xhs_session.json
```

### IP代理池配置

代理池是可选的，如果需要使用：

1. **在代码中配置**:
```python
from xhs.proxy_pool import ProxyPool

proxies = [
    "http://proxy1.com:8080",
    "http://proxy2.com:8080",
]
proxy_pool = ProxyPool(proxies)
```

2. **通过环境变量配置**（未来可扩展）:
```bash
export XHS_PROXIES="proxy1,proxy2,proxy3"
```

---

## 📊 API端点汇总

| 端点 | 方法 | 功能 | 状态 |
|------|------|------|------|
| `/health` | GET | 健康检查 | ✅ |
| `/set-cookies` | POST | 设置Cookie | ✅ |
| `/search` | POST | 关键词搜索 | ✅ |
| `/note/detail` | POST | 获取笔记详情 | ✅ |
| `/note/from-url` | POST | 从URL获取笔记 | ✅ |
| `/notes/by-ids` | POST | 批量获取笔记 | 🆕 |
| `/comments` | POST | 获取评论（支持二级） | 🆕 |
| `/user/notes` | POST | 获取用户笔记列表 | 🆕 |
| `/user/info` | POST | 获取用户信息 | 🆕 |
| `/wordcloud` | POST | 生成词云图 | 🆕 |

---

## 💡 使用建议

### 小规模爬取（< 100条/天）
- ✅ 不需要代理池
- ✅ 使用登录态缓存即可
- ✅ 控制请求频率（建议 > 2秒/请求）

### 中规模爬取（100-1000条/天）
- ✅ 建议使用代理池（3-5个代理）
- ✅ 必须使用登录态缓存
- ✅ 控制请求频率（建议 > 1秒/请求）

### 大规模爬取（> 1000条/天）
- ✅ 必须使用代理池（10+个代理）
- ✅ 必须使用登录态缓存
- ✅ 建议使用住宅代理
- ✅ 严格控制请求频率（建议 > 0.5秒/请求）
- ⚠️ 注意遵守平台规则，避免过度爬取

---

## ⚠️ 免责声明

本项目仅供学习研究使用，请遵守：
- 小红书平台的使用条款
- 相关法律法规
- 不要用于商业用途
- 不要过度爬取，影响平台服务

---

## 📚 参考资源

- [MediaCrawler 项目](https://github.com/suse00544/MediaCrawler) - 参考实现
- [小红书签名仓库](https://github.com/Cloxl/xhs) - 签名算法参考
- [Playwright 文档](https://playwright.dev/) - 浏览器自动化

